from tkinter import Frame
from turtle import width
import cv2
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from PIL import Image
import PIL.ImageOps
import os, ssl, time


#Setting an HTTPS Context to fetch data from OpenML

if (not os.environ.get('PYTHONHTTPSVERIFY', '') and
    getattr(ssl, '_create_unverified_context', None)): 
    ssl._create_default_https_context = ssl._create_unverified_context

# Fetching the data

X, y = fetch_openml('mnist_784', version=1, return_X_y=True)
print(pd.Series(y).value_counts())
classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
nclasses = len(classes)


#Splitting the data and scaling it

X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=9,train_size=7500,test_size=2500)
#scaling the features
X_train_scaled=X_train/255.0
X_test_scaled =X_test/255.0

clf = LogisticRegression(solver = 'saga', multi_class =' multinomial').fit(X_train_scaled, y_train)

#Calculating the accuracy of the model

y_pred = clf.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy")

#Starting the camera

cap = cv2.VideoCapture(0)
while(True):
    try:
        ret,frame = cap.read()
        
        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)

        #Drawing a box in the center of the video
        height, width = gray.shape
        upperleft = (int(width/2 - 56), int(height/2 - 56))
        bottomright = (int(width/2 + 56), int(height/2 + 56))
        cv2.rectangle(gray, upperleft, bottomright, (0, 255, 0),2)
        
        roi = gray[upperleft[1]:bottomright[1], upperleft[0]:bottomright[0]]
       
        #Converting cv2 image to pil format
        im_pil = Image.fromarray(roi)
        image_bw = im_pil.convert('L')
        image_bw_resized = image_bw.resize((28, 28), Image.ANTIALIAS)

        image_bw_resized_inverted = PIL.ImageOps.invert(image_bw_resized)
        pixel_filter = 20
        min_pixel = np.percentile(image_bw_resized_inverted, pixel_filter)
        image_bw_resized_inverted_scaled = np.clip(image_bw_resized_inverted - min_pixel, 0, 255)
        max_pixel = np.max(image_bw_resized_inverted)
        image_bw_resized_inverted_scaled = np.asarray(image_bw_resized_inverted_scaled)/max_pixel
        
        test_sample = np.array(image_bw_resized_inverted_scaled).reshape(1, 784)
        test_pred = clf.predict(test_sample)
        print("test_pred")
        # Display the resulting frame
        cv2.imshow('frame', gray)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    except Exception as e:
        pass

cap.release()
cv2.destroyallwindows()
